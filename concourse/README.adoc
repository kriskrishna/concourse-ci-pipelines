// Do not edit this file (e.g. go instead to docs/)
:jenkins-root-docs: https://raw.githubusercontent.com/spring-cloud/spring-cloud-pipelines/master/docs/img/jenkins
:concourse-root-docs: https://raw.githubusercontent.com/spring-cloud/spring-cloud-pipelines/master/docs/img/concourse
:intro-root-docs: https://raw.githubusercontent.com/spring-cloud/spring-cloud-pipelines/master/docs/img/intro
== Concourse Pipeline [[concourse]]

The repository contains a pipeline that will build and deploy  - https://git.web.boeing.com/dte_replatforming/sample-spring-cloud-svc[Sample Spring Cloud Service] application.

Start https://github.com/spring-cloud/spring-cloud-pipelines/tree/master/concourse#concourse-pipeline[here], if you would rather deploy the sample applications that are used with the Spring Cloud Pipelines http://cloud.spring.io/spring-cloud-pipelines/spring-cloud-pipelines.html[documentation].

=== Step by step

If you want to just run the demo as far as possible using PCF Dev and Docker Compose

- <<fork,Fork repos>>
- <<start,Start Concourse and Artifactory>>
- <<pcfdev,Start PCF Dev (if you don't want to use an existing one)>>
- <<fly,Setup the `fly` CLI>>
- <<creds,Setup your `credentials.yml`>>
- <<pipeline,Run the `sample-spring-cloud-svc` pipeline>>

==== Fork repos

[[fork]] There is only 1 app that is used by the pipeline. You only need to fork this repo so your user is able to tag and push the tag to repo.

  - https://git.web.boeing.com/dte_replatforming/sample-spring-cloud-svc[Sample Spring Cloud Service]

==== Start Concourse and Artifactory

[[start]] Concourse + Artifactory can be run locally. To do that just execute the
`start.sh` script from this repo.

[source,bash]
----
git clone https://git.web.boeing.com/dte_replatforming/ci-pipelines
cd ci-pipelines/concourse
./setup_docker_compose.sh
./start.sh 192.168.99.100
----

The `setup_docker_compose.sh` script should be executed once only to allow
generation of keys.

The `192.168.99.100` param is an example of an external URL of Concourse
(equal to Docker-Machine ip in this example).

Then Concourse will be running on port `8080` and Artifactory `8081`.

==== Start PCF Dev

[[pcfdev]] TIP: You can skip this step if you have CF installed and don't want to use PCF Dev
The only thing you have to do is to set up spaces.

WARNING: It's more than likely that you'll run out of resources when you reach stage step.
Don't worry! Keep calm and <<resources,clear some apps from PCF Dev and continue>>.

You have to download and start PCF Dev. https://pivotal.io/platform/pcf-tutorials/getting-started-with-pivotal-cloud-foundry-dev/install-pcf-dev[A link how to do it is available here.]

The default credentials when using PCF Dev are:

[source,bash]
----
username: user
password: pass
email: user
org: pcfdev-org
space: pcfdev-space
api: api.local.pcfdev.io
----

You can start the PCF dev like this:

[source,bash]
----
cf dev start
----

You'll have to create 3 separate spaces (email admin, pass admin)

[source,bash]
----
cf login -a https://api.local.pcfdev.io --skip-ssl-validation -u admin -p admin -o pcfdev-org

cf create-space pcfdev-test
cf set-space-role user pcfdev-org pcfdev-test SpaceDeveloper
cf create-space pcfdev-stage
cf set-space-role user pcfdev-org pcfdev-stage SpaceDeveloper
cf create-space pcfdev-prod
cf set-space-role user pcfdev-org pcfdev-prod SpaceDeveloper
----

You can also execute the `./tools/pcfdev-helper.sh setup-spaces` to do this.

==== Setup the `fly` CLI

[[fly]] If you go to Concourse website you should see sth like this:

{nbsp}
{nbsp}

image::{concourse-root-docs}/running_concourse.png[]

{nbsp}
{nbsp}

You can click one of the icons (depending on your OS) to download `fly`, which is the Concourse CLI. Once you've downloaded that (and maybe added to your PATH) you can run:

[source,bash]
----
fly --version
----

If `fly` is properly installed then it should print out the version.

==== Setup your `credentials.yml`

[[creds]] The repo comes with `credentials-sample.yml` which is set up with sample data (most credentials) are set to be applicable for PCF Dev. Copy this file to a new file `credentials.yml` (the file is added to .gitignore so don't worry that you'll push it with your passwords) and edit it as you wish. For our demo jus setup:

  - `app-url` - url pointing to your forked `sample-spring-cloud-svc` repo
  - `github-private-key` - your private key to clone / tag GitHub repos
  - `repo-with-jars` - the IP is set to the defaults for Docker Machine. You should update it to point to your setup

If you don't have a Docker Machine just execute `./whats_my_ip.sh` script to
get an external IP that you can pass to your `repo-with-jars` instead of the default
Docker Machine IP.

Below you can see what environment variables are required by the scripts. To the right hand side you can see the default values for PCF Dev that we set in the `credentials-sample.yml`.

[frame="topbot",options="header,footer"]
|======================
|Property Name  | Property Description | Default value
|CF_TEST_API_URL | The URL to the CF Api for TEST env| api.local.pcfdev.io
|CF_STAGE_API_URL | The URL to the CF Api for STAGE env | api.local.pcfdev.io
|CF_PROD_API_URL | The URL to the CF Api for PROD env | api.local.pcfdev.io
|CF_TEST_ORG    | Name of the org for the test env | pcfdev-org
|CF_TEST_SPACE  | Name of the space for the test env | pcfdev-space
|CF_STAGE_ORG   | Name of the org for the stage env | pcfdev-org
|CF_STAGE_SPACE | Name of the space for the stage env | pcfdev-space
|CF_PROD_ORG   | Name of the org for the prod env | pcfdev-org
|CF_PROD_SPACE | Name of the space for the prod env | pcfdev-space
|REPO_WITH_JARS | URL to repo with the deployed jars | http://192.168.99.100:8081/artifactory/libs-release-local
|M2_SETTINGS_REPO_ID | The id of server from Maven settings.xml | artifactory-local
|CF_HOSTNAME_UUID | Additional suffix for the route. In a shared environment the default routes can be already taken |
|======================

==== Build the pipeline

Log in (e.g. for Concourse running at `192.168.99.100` - if you don't provide any value then `localhost` is assumed). If you execute this script  (it assumes that either `fly` is on your `PATH` or it's in the same folder as the script is):

[source,bash]
----
./login.sh 192.168.99.100
----

Next run the command to create the pipeline.

[source,bash]
----
./set_pipeline.sh
----

Then you'll create a `sample-spring-cloud-svc` pipeline under the `docker` alias, using the provided `credentials.yml` file.
You can override these values in exactly that order (e.g. `./set-pipeline.sh some-project another-target some-other-credentials.yml`)

==== Run the `sample-spring-cloud-svc` pipeline

[[pipeline]]
{nbsp}
{nbsp}

image::{concourse-root-docs}/concourse_login.png[caption="Step 1: ", title="Click `Login`"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/concourse_team_main.png[caption="Step 2: ", title="Pick `main` team"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/concourse_user_pass.png[caption="Step 3: ", title="Log in with `concourse` user and `changeme` password"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/concourse_pipeline.png[caption="Step 4: ", title="Your screen should look more or less like this"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/start_pipeline.png[caption="Step 5: ", title="Unpause the pipeline by clicking in the top lefr corner and then clicking the `play` button"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/generate_version.png[caption="Step 6: ", title="Click 'generate-version'"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/run_pipeline.png[caption="Step 7: ", title="Click `+` sign to start a new build"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/concourse_pending.png[caption="Step 8: ", title="The job is pending"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/job_running.png[caption="Step 9: ", title="Job is pending in the main screen"]

{nbsp}
{nbsp}

image::{concourse-root-docs}/running_pipeline.png[caption="Step 10: ", title="Job is running in the main screen"]

=== FAQ

[[faq]]

==== Can I use the pipeline for some other repos?

Sure! Just change the `app-url` in `credentials.yml`!

==== Will this work for ANY project out of the box?

Not really. This is an `opinionated pipeline` that's why we took some
opinionated decisions like:

- usage of Spring Cloud, Spring Cloud Contract Stub Runner and Spring Cloud Eureka
- application deployment to Cloud Foundry
- For Maven:
    * usage of Maven Wrapper
    * artifacts deployment by `./mvnw clean deploy`
    * `stubrunner.ids` property to retrieve list of collaborators for which stubs should be downloaded
    * running smoke tests on a deployed app via the `smoke` Maven profile
    * running end to end tests on a deployed app via the `e2e` Maven profile
- For Gradle (in the `github-analytics` application check the `gradle/pipeline.gradle` file):
    * usage of Gradlew Wrapper
    * `deploy` task for artifacts deployment
    * running smoke tests on a deployed app via the `smoke` task
    * running end to end tests on a deployed app via the `e2e` task
    * `groupId` task to retrieve group id
    * `artifactId` task to retrieve artifact id
    * `currentVersion` task to retrieve the current version
    * `stubIds` task to retrieve list of collaborators for which stubs should be downloaded

This is the initial approach that can be easily changed in the future.
In our version of the pipeline, however, we removed the requirements for Spring Cloud Contract Stub Runner and Spring Cloud Eureka.

==== Can I modify this to reuse in my project?

Sure! It's open-source! The important thing is that the core part of the logic is written in
Bash scripts. That way, in the majority of cases, you could change only the bash scripts without changing the
whole pipeline. https://github.com/spring-cloud/spring-cloud-pipelines/tree/master/common/src/main/bash[You can check out the scripts here.]

==== I ran out of resources!!

[[resources]] When deploying the app to stage or prod you can get an exception `Insufficient resources`. The way to
 solve it is to kill some apps from test / stage env. To achieve that just call

[source,bash]
----
cf target -o pcfdev-org -s pcfdev-test
cf stop sample-spring-cloud-svc
----

You can also execute `./tools/pcfdev-helper.sh kill-all-apps` that will remove
all demo-related apps deployed to PCF dev.

==== The rollback step fails due to missing JAR ?!

You must have pushed some tags and have removed the Artifactory volume that
contained them. To fix this, just remove the tags

[source,bash]
----
git tag -l | xargs -n 1 git push --delete origin
----

==== Can I see the output of a job from the terminal?

Yes! Assuming that pieline name is `sample-spring-cloud-svc` and job name is `build-and-upload` you can running

[source,bash]
----
fly watch --job sample-spring-cloud-svc/build-and-upload -t docker
----

==== I clicked the job and it's constantly pending...

Don't worry... most likely you've just forgotten to click the `play` button to
unpause the pipeline. Click to the top left, expand the list of pipelines and click
the `play` button next to `sample-spring-cloud-svc`.

Another problem that might occur is that you need to have the `version` branch.
Concourse will wait for the `version` branch to appear in your repo. So in order for
the pipeline to start ensure that when doing some git operations you haven't
forgotten to create / copy the `version` branch too.

==== The route is already in use

If you play around with Jenkins / Concourse you might end up with the routes occupied

[source,bash]
----
Using route sample-spring-cloud-svc-test.local.pcfdev.io
Binding sample-spring-cloud-svc-test.local.pcfdev.io to sample-spring-cloud-svc...
FAILED
The route sample-spring-cloud-svc-test.local.pcfdev.io is already in use.
----

Just delete the routes

[source,bash]
----
yes | cf delete-route local.pcfdev.io -n sample-spring-cloud-svc-test
yes | cf delete-route local.pcfdev.io -n sample-spring-cloud-svc-stage
yes | cf delete-route local.pcfdev.io -n sample-spring-cloud-svc-prod
----

You can also execute the `./tools/pcfdev-helper.sh delete-routes`

==== I'm unauthorized to deploy infrastructure jars

Most likely you've forgotten to update your local `settings.xml` with the Artifactory's
setup. Check out <<settings,this section of the docs and update your `settings.xml`>>.